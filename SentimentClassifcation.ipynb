{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment pipepline\n",
    "\n",
    "Write down your tweet, and roBERTa will found out its sentiment and the words that reflect this sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from transformers import *\n",
    "import tokenizers\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "max_length = 96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = tokenizers.ByteLevelBPETokenizer(\n",
    "    vocab= path + '/vocab.json',\n",
    "    merges = path + '/merges.txt',\n",
    "    lowercase = True, #All tokens are in lower case\n",
    "    add_prefix_space=True #Do not treat spaces like part of the tokens\n",
    ")\n",
    "\n",
    "sentiment_id = {'positive': [1, 0, 0], 'negative': [0, 0, 1], 'neutral': [0, 1, 0]} \n",
    "sentiment_rev = ['positive', 'neutral', 'negative']\n",
    "sentiment_token_id = {'positive': 1313, 'negative': 2430, 'neutral': 7974} \n",
    "\n",
    "train_set = pd.read_csv(path+'/train.csv').fillna('')\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating models' architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_model():\n",
    "    ids = tf.keras.layers.Input((max_length,), dtype=tf.int32)\n",
    "    att = tf.keras.layers.Input((max_length,), dtype=tf.int32)\n",
    "    tok = tf.keras.layers.Input((max_length,), dtype=tf.int32)\n",
    "\n",
    "    config = RobertaConfig.from_pretrained(path+'/config-roberta-base.json')\n",
    "    bert_model = TFRobertaModel.from_pretrained(path+'/pretrained-roberta-base.h5',config=config)\n",
    "    x = bert_model(ids,attention_mask=att,token_type_ids=tok)\n",
    "        \n",
    "    x3 = tf.keras.layers.Dropout(0.1)(x[0])\n",
    "    x3 = tf.keras.layers.Conv1D(8, 2, padding='same')(x3) #3\n",
    "    x3 = tf.keras.layers.LeakyReLU()(x3)\n",
    "    x3 = tf.keras.layers.Conv1D(4, 2, padding='same')(x3) #3\n",
    "    x3 = tf.keras.layers.Flatten()(x3)\n",
    "    #x3 = tf.keras.layers.Dense(16, activation='relu')(x3) #uncommented\n",
    "    x3 = tf.keras.layers.Dense(8, activation='relu')(x3)\n",
    "    x3 = tf.keras.layers.Dense(3, activation='relu')(x3)\n",
    "    x3 = tf.keras.layers.Activation('softmax')(x3)\n",
    "    \n",
    "\n",
    "    model = tf.keras.models.Model(inputs=[ids, att, tok], outputs=[x3])\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_model():\n",
    "    ids = tf.keras.layers.Input((max_length,), dtype=tf.int32)\n",
    "    att = tf.keras.layers.Input((max_length,), dtype=tf.int32)\n",
    "    tok = tf.keras.layers.Input((max_length,), dtype=tf.int32)\n",
    "\n",
    "    config = RobertaConfig.from_pretrained(path+'/config-roberta-base.json')\n",
    "    bert_model = TFRobertaModel.from_pretrained(path+'/pretrained-roberta-base.h5',config=config)\n",
    "    x = bert_model(ids,attention_mask=att,token_type_ids=tok)\n",
    "    \n",
    "    x1 = tf.keras.layers.Dropout(0.1)(x[0])\n",
    "    x1 = tf.keras.layers.Conv1D(filters=128, kernel_size=2, padding='same')(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.Conv1D(filters=64, kernel_size=2, padding='same')(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.Conv1D(filters=32, kernel_size=2, padding='same')(x1)\n",
    "    x1 = tf.keras.layers.Dense(units=1)(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.Flatten()(x1)\n",
    "    x1 = tf.keras.layers.Activation('softmax')(x1)\n",
    "    \n",
    "    x2 = tf.keras.layers.Dropout(0.1)(x[0])\n",
    "    x2 = tf.keras.layers.Conv1D(filters=128, kernel_size=2, padding='same')(x2)\n",
    "    x2 = tf.keras.layers.LeakyReLU()(x2)\n",
    "    x2 = tf.keras.layers.Conv1D(filters=64, kernel_size=2, padding='same')(x2)\n",
    "    x2 = tf.keras.layers.LeakyReLU()(x2)\n",
    "    x2 = tf.keras.layers.Conv1D(filters=32, kernel_size=2, padding='same')(x2)\n",
    "    x2 = tf.keras.layers.Dense(units=1)(x2)\n",
    "    x2 = tf.keras.layers.LeakyReLU()(x2)\n",
    "    x2 = tf.keras.layers.Flatten()(x2)\n",
    "    x2 = tf.keras.layers.Activation('softmax')(x2)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=[ids, att, tok], outputs=[x1,x2])\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaModel.\n",
      "\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at /home/lucas/Documents/PO-240/sentiment-extraction/pretrained-roberta-base.h5.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFRobertaModel.\n",
      "\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at /home/lucas/Documents/PO-240/sentiment-extraction/pretrained-roberta-base.h5.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "extract_m = extract_model()\n",
    "extract_m.load_weights(path+'/v0-roberta-4-extract.h5')\n",
    "\n",
    "classify_m = classify_model()\n",
    "classify_m.load_weights(path+'/v1-roberta-ext-1-classify.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict tweet sentiment\n",
    "\n",
    "Type your tweet below and roBERTa will predict its sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = np.ones((1, max_length), dtype='int32')\n",
    "attention_mask = np.zeros((1, max_length), dtype='int32')\n",
    "token_type_ids = np.zeros((1, max_length),dtype='int32')\n",
    "\n",
    "\n",
    "#Type your tweet here\n",
    "text = 'Ford Brasi\\'s decision to close its factories is partly a result of Ford\\'s global woes. It also shows the weakness of Brazilian manufacturing'\n",
    "if len(text) > 140:\n",
    "    raise Exception('Text too big')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 958us/step\n",
      "\n",
      "Sentiment:  negative\n"
     ]
    }
   ],
   "source": [
    "text1 = \" \" + \" \".join(text.split())\n",
    "enc = tokenizer.encode(text1)\n",
    "input_ids[0, :len(enc.ids)+2] = [0] + enc.ids + [2]\n",
    "attention_mask[0, :len(enc.ids)+2] = 1\n",
    "\n",
    "result = classify_m.predict([input_ids, attention_mask, token_type_ids], verbose=True)\n",
    "s_id = np.argmax(result[0])\n",
    "print()\n",
    "print('Sentiment: ', sentiment_rev[s_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step\n",
      "\n",
      "Selected text:\n",
      " woes. it also shows the weakness of brazilian manufacturing\n"
     ]
    }
   ],
   "source": [
    "sentiment_token = sentiment_token_id[sentiment_rev[s_id]]\n",
    "input_ids[0, :len(enc.ids)+5] = [0] + enc.ids + [2,2] + [sentiment_token] + [2]\n",
    "attention_mask[0, :len(enc.ids)+5] = 1\n",
    "\n",
    "start, end = extract_m.predict([input_ids, attention_mask, token_type_ids], verbose=True)\n",
    "start_idx = np.argmax(start)\n",
    "end_idx = np.argmax(end)\n",
    "selected_text = tokenizer.decode(enc.ids[start_idx-1:end_idx])\n",
    "print('\\nSelected text:')\n",
    "print(selected_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
